{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cad1b08-1344-4ed5-a05e-727348b145fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sspowar/cslab/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import hamming\n",
    "from srmrpy.hilbert import hilbert\n",
    "from srmrpy.modulation_filters import *\n",
    "from gammatone.fftweight import fft_gtgram\n",
    "from gammatone.filters import centre_freqs, make_erb_filters, erb_filterbank\n",
    "from srmrpy.segmentaxis import segment_axis\n",
    "from scipy.io.wavfile import read as readwav\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0373c532-2ed1-473c-8bb4-23e14ab21c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/sspowar/scratch/archive/LA/LA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4847f0ae-f26e-451e-884a-5945c49cccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 25380\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "train_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt',\n",
    "                       sep=\" \", header=None)\n",
    "train_df.columns =['speaker_id','filename','system_id','type','class_name']\n",
    "# train_df.drop(columns=['null'],inplace=True)\n",
    "train_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_train/flac/'+train_df.filename+'.flac'\n",
    "train_df['target'] = (train_df.class_name=='spoof').astype('int32') # set labels 1 for fake and 0 for real\n",
    "# if DEBUG:\n",
    "#     train_df = train_df.groupby(['target']).sample(2500).reset_index(drop=True)\n",
    "print(f'Train Samples: {len(train_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa31676-b5d5-419c-9432-3a736ec862b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>system_id</th>\n",
       "      <th>type</th>\n",
       "      <th>class_name</th>\n",
       "      <th>filepath</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LA_0079</td>\n",
       "      <td>LA_T_1138215</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>/home/sspowar/scratch/archive/LA/LA/ASVspoof20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LA_0079</td>\n",
       "      <td>LA_T_1271820</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>/home/sspowar/scratch/archive/LA/LA/ASVspoof20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LA_0079</td>\n",
       "      <td>LA_T_1272637</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>/home/sspowar/scratch/archive/LA/LA/ASVspoof20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LA_0079</td>\n",
       "      <td>LA_T_1276960</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>/home/sspowar/scratch/archive/LA/LA/ASVspoof20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LA_0079</td>\n",
       "      <td>LA_T_1341447</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>bonafide</td>\n",
       "      <td>/home/sspowar/scratch/archive/LA/LA/ASVspoof20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker_id      filename system_id type class_name  \\\n",
       "0    LA_0079  LA_T_1138215         -    -   bonafide   \n",
       "1    LA_0079  LA_T_1271820         -    -   bonafide   \n",
       "2    LA_0079  LA_T_1272637         -    -   bonafide   \n",
       "3    LA_0079  LA_T_1276960         -    -   bonafide   \n",
       "4    LA_0079  LA_T_1341447         -    -   bonafide   \n",
       "\n",
       "                                            filepath  target  \n",
       "0  /home/sspowar/scratch/archive/LA/LA/ASVspoof20...       0  \n",
       "1  /home/sspowar/scratch/archive/LA/LA/ASVspoof20...       0  \n",
       "2  /home/sspowar/scratch/archive/LA/LA/ASVspoof20...       0  \n",
       "3  /home/sspowar/scratch/archive/LA/LA/ASVspoof20...       0  \n",
       "4  /home/sspowar/scratch/archive/LA/LA/ASVspoof20...       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b91c5057-4965-4b93-b8f4-f453c6abba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_erbs(low_freq, fs, n_filters):\n",
    "    ear_q = 9.26449 # Glasberg and Moore Parameters\n",
    "    min_bw = 24.7\n",
    "    order = 1\n",
    "\n",
    "    erbs = ((centre_freqs(fs, n_filters, low_freq)/ear_q)**order + min_bw**order)**(1/order)\n",
    "    return erbs\n",
    "\n",
    "def calc_cutoffs(cfs, fs, q):\n",
    "    # Calculates cutoff frequencies (3 dB) for 2nd order bandpass\n",
    "    w0 = 2*np.pi*cfs/fs\n",
    "    B0 = np.tan(w0/2)/q\n",
    "    L = cfs - (B0 * fs / (2*np.pi))\n",
    "    R = cfs + (B0 * fs / (2*np.pi))\n",
    "    return L, R\n",
    "\n",
    "def normalize_energy(energy, drange=30.0):\n",
    "    peak_energy = np.max(np.mean(energy, axis=0))\n",
    "    min_energy = peak_energy*10.0**(-drange/10.0)\n",
    "    energy[energy < min_energy] = min_energy\n",
    "    energy[energy > peak_energy] = peak_energy\n",
    "    return energy\n",
    "\n",
    "def srmr(x, fs, n_cochlear_filters=23, low_freq=125, min_cf=4, max_cf=128, fast=True, norm=False):\n",
    "    wLengthS = .256\n",
    "    wIncS = .064\n",
    "    # Computing gammatone envelopes\n",
    "    if fast:\n",
    "        mfs = 400.0\n",
    "        gt_env = fft_gtgram(x, fs, 0.010, 0.0025, n_cochlear_filters, low_freq)\n",
    "    else:\n",
    "        cfs = centre_freqs(fs, n_cochlear_filters, low_freq)\n",
    "        fcoefs = make_erb_filters(fs, cfs)\n",
    "        gt_env = np.abs(hilbert(erb_filterbank(x, fcoefs)))\n",
    "        mfs = fs\n",
    "\n",
    "    wLength = int(np.ceil(wLengthS*mfs))\n",
    "    wInc = int(np.ceil(wIncS*mfs))\n",
    "\n",
    "    # Computing modulation filterbank with Q = 2 and 8 channels\n",
    "    mod_filter_cfs = compute_modulation_cfs(min_cf, max_cf, 8)\n",
    "    MF = modulation_filterbank(mod_filter_cfs, mfs, 2)\n",
    "\n",
    "    n_frames = int(1 + (gt_env.shape[1] - wLength)//wInc)\n",
    "    w = hamming(wLength+1)[:-1] # window is periodic, not symmetric\n",
    "\n",
    "    energy = np.zeros((n_cochlear_filters, 8, n_frames))\n",
    "    for i, ac_ch in enumerate(gt_env):\n",
    "        mod_out = modfilt(MF, ac_ch)\n",
    "        for j, mod_ch in enumerate(mod_out):\n",
    "            mod_out_frame = segment_axis(mod_ch, wLength, overlap=wLength-wInc, end='pad')\n",
    "            energy[i,j,:] = np.sum((w*mod_out_frame[:n_frames])**2, axis=1)\n",
    "\n",
    "    if norm:\n",
    "        energy = normalize_energy(energy)\n",
    "\n",
    "    erbs = np.flipud(calc_erbs(low_freq, fs, n_cochlear_filters))\n",
    "\n",
    "    avg_energy = np.mean(energy, axis=2)\n",
    "    total_energy = np.sum(avg_energy)\n",
    "\n",
    "    AC_energy = np.sum(avg_energy, axis=1)\n",
    "    AC_perc = AC_energy*100/total_energy\n",
    "\n",
    "    AC_perc_cumsum=np.cumsum(np.flipud(AC_perc))\n",
    "    K90perc_idx = np.where(AC_perc_cumsum>90)[0][0]\n",
    "\n",
    "    BW = erbs[K90perc_idx]\n",
    "\n",
    "    cutoffs = calc_cutoffs(mod_filter_cfs, fs, 2)[0]\n",
    "\n",
    "    if (BW > cutoffs[4]) and (BW < cutoffs[5]):\n",
    "        Kstar=5\n",
    "    elif (BW > cutoffs[5]) and (BW < cutoffs[6]):\n",
    "        Kstar=6\n",
    "    elif (BW > cutoffs[6]) and (BW < cutoffs[7]):\n",
    "        Kstar=7\n",
    "    elif (BW > cutoffs[7]):\n",
    "        Kstar=8\n",
    "\n",
    "    return np.sum(avg_energy[:, :4])/np.sum(avg_energy[:, 4:Kstar]), energy\n",
    "\n",
    "\n",
    "def read_audio_file(filename, max_length=64600):\n",
    "    # Use soundfile to read the .flac audio file\n",
    "    audio_data, fs = sf.read(filename, always_2d=True, dtype='float32')\n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    audio_data /= np.max(np.abs(audio_data))\n",
    "\n",
    "    # Pad or truncate audio data to the desired max_length\n",
    "    if len(audio_data) < max_length:\n",
    "        padding = max_length - len(audio_data)\n",
    "        audio_data = np.pad(audio_data, ((0, padding), (0, 0)), mode='constant')\n",
    "    elif len(audio_data) > max_length:\n",
    "        audio_data = audio_data[:max_length, :]\n",
    "    return fs, audio_data\n",
    "\n",
    "def process_file(f, n_cochlear_filters=23, low_freq=125, min_cf=4, max_cf=128, fast=True, norm=True):\n",
    "    fs, s = read_audio_file(f)  # Use read_audio_file to handle .flac files\n",
    "    if len(s.shape) > 1:\n",
    "        s = s[:, 0]\n",
    "    r, energy = srmr(s, fs, n_cochlear_filters=n_cochlear_filters,\n",
    "                     min_cf=min_cf,\n",
    "                     max_cf=max_cf,\n",
    "                     fast=fast,\n",
    "                     norm=norm)\n",
    "    return energy, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "076972cf-cffd-417a-8950-cc89a420d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRMRDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        filepath = row['filepath']\n",
    "        target = row['target']\n",
    "\n",
    "        # Read the audio file and calculate SRMR\n",
    "        energy, r = process_file(filepath)\n",
    "        \n",
    "        # Convert NumPy array to PyTorch tensor\n",
    "        energy = torch.tensor(energy, dtype=torch.double)\n",
    "        return energy, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0c98945-17f4-4945-9142-8eb49e751b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "def calculate_eer(y_true, y_scores):\n",
    "    fpr, fnr, thresholds = roc_curve(y_true, y_scores, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - fnr)))]\n",
    "    return eer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8372eec8-6479-4959-97a3-ae82887ad732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False)):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_labels = (output > 0.5).float()  # Assuming 0.5 threshold for binary classification\n",
    "        total_correct += (predicted_labels == target).sum().item()\n",
    "        total_samples += target.size(0)\n",
    "\n",
    "        # Store true labels and predicted scores for EER calculation\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_scores.extend(output.cpu().detach().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    eer = calculate_eer(np.array(y_true), np.array(y_scores))\n",
    "    return avg_loss, accuracy, eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f81cc65-ccd3-4d9c-9c6b-43b2cea1b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN_Model(nn.Module):\n",
    "    def __init__(self, num_class:int, msr_size:tuple, rnn_hidden_size:int, dropout:float, tem_fac:list):\n",
    "        super(CRNN_Model, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.dp = nn.Dropout(p=dropout)\n",
    "        self.num_freq = msr_size[0]\n",
    "        self.num_mod = msr_size[1]\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.tem_fac = tem_fac\n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.MaxPool3d((self.tem_fac[0], 1, 1)),\n",
    "            self.relu\n",
    "        )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(16),\n",
    "            nn.MaxPool3d((self.tem_fac[1], 1, 1)),\n",
    "            self.relu\n",
    "        )\n",
    "        \n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(4),\n",
    "            nn.MaxPool3d((self.tem_fac[2], 1, 1)),\n",
    "            self.relu\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.downsample = nn.MaxPool3d((2,2,2))\n",
    "        \n",
    "        self.CNNblock = nn.Sequential(\n",
    "            self.cnn1,\n",
    "            self.cnn2,\n",
    "            self.cnn3\n",
    "            )\n",
    "        \n",
    "        # self.Att = CBAM_Att(channel=4)\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(20416, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            self.relu,\n",
    "            self.dp\n",
    "            )\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn1 = nn.GRU(input_size=128, \n",
    "                            hidden_size=self.rnn_hidden_size,\n",
    "                            num_layers=3,\n",
    "                            bidirectional=True, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm([2*self.rnn_hidden_size,int(150/np.product(self.tem_fac))])\n",
    "        self.maxpool = nn.MaxPool1d(int(150/np.product(self.tem_fac)))\n",
    "        \n",
    "        self.fc2 = nn.Linear(self.rnn_hidden_size*2, 1)\n",
    "        \n",
    "        self.initialize_weights()\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply the CNN layers\n",
    "        # print(x.shape)\n",
    "        x = x.unsqueeze(1) \n",
    "        # print(x.shape)\n",
    "        ot = self.CNNblock(x)\n",
    "        # Flatten ot to have shape (batch_size, -1)\n",
    "        ot = ot.view(ot.size(0), -1)\n",
    "\n",
    "        # print(ot.shape)\n",
    "        # Pass through the first fully connected layer\n",
    "        ot = self.fc1(ot)\n",
    "        # print(ot.shape)   \n",
    "        # After the RNN layer, ot will have shape (batch_size, time_steps, rnn_hidden_size * 2)\n",
    "        ot, _ = self.rnn1(ot)\n",
    "        # print(\"RNN\", ot.shape)\n",
    "        \n",
    "        ot = self.fc2(ot).squeeze(1).float()\n",
    "        ot = torch.sigmoid(ot)\n",
    "        # print(\"After FC2\", ot.shape, ot)\n",
    "        \n",
    "        return ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "855b499d-9505-4a86-a543-cc2b1b36d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SRMRDataset(train_df[:5000])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef59549-d75c-496a-a51b-d32545a130cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                             | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3916, 0.3902, 0.3758, 0.3621, 0.3549, 0.3676, 0.3811, 0.3910, 0.4057,\n",
      "        0.4185, 0.4174, 0.4542, 0.4680, 0.4898, 0.4990, 0.5049],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                   | 1/313 [00:26<2:15:49, 26.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3276, 0.2986, 0.2452, 0.2247, 0.2040, 0.1830, 0.1656, 0.1416, 0.1126,\n",
      "        0.1154, 0.1440, 0.1738, 0.2307, 0.2527, 0.2791, 0.3461],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▏                                  | 2/313 [00:35<1:23:57, 16.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3123, 0.2836, 0.2669, 0.2291, 0.1936, 0.1761, 0.1526, 0.1398, 0.1303,\n",
      "        0.1198, 0.1313, 0.1538, 0.1516, 0.1454, 0.1709, 0.2051],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▎                                  | 3/313 [00:47<1:13:27, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3804, 0.2793, 0.2306, 0.1850, 0.1987, 0.2497, 0.2471, 0.2629, 0.2444,\n",
      "        0.1983, 0.1714, 0.1620, 0.1841, 0.1864, 0.2256, 0.2253],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   1%|▍                                  | 4/313 [00:59<1:09:06, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.7251, 0.7492, 0.7564, 0.6892, 0.5378, 0.4197, 0.3983, 0.3778, 0.2687,\n",
      "        0.2383, 0.2074, 0.2024, 0.2129, 0.2437, 0.2465, 0.3183],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▌                                  | 5/313 [01:12<1:08:50, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.4369, 0.4347, 0.5220, 0.4818, 0.4520, 0.4904, 0.6345, 0.7672, 0.8334,\n",
      "        0.8360, 0.7918, 0.6428, 0.4442, 0.4086, 0.3660, 0.3408],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▋                                  | 6/313 [01:21<1:01:04, 11.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.6181, 0.5788, 0.4064, 0.2866, 0.2831, 0.4393, 0.5145, 0.5609, 0.5431,\n",
      "        0.5205, 0.5252, 0.5083, 0.3260, 0.2167, 0.1819, 0.2581],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|▊                                    | 7/313 [01:30<55:26, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.6551, 0.6678, 0.6823, 0.7771, 0.8666, 0.8700, 0.6838, 0.4921, 0.3110,\n",
      "        0.1804, 0.1362, 0.1268, 0.1384, 0.1875, 0.3527, 0.3876],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|▉                                    | 8/313 [01:39<52:17, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3913, 0.3489, 0.4841, 0.3277, 0.3610, 0.6363, 0.7409, 0.6669, 0.4724,\n",
      "        0.3694, 0.4676, 0.5140, 0.2974, 0.2607, 0.2113, 0.3230],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|█                                    | 9/313 [01:48<50:16,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.3109, 0.2093, 0.1902, 0.1416, 0.2013, 0.2113, 0.1004, 0.0886, 0.1236,\n",
      "        0.0708, 0.0178, 0.0082, 0.0087, 0.0168, 0.1131, 0.3148],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   3%|█▏                                  | 10/313 [01:58<49:23,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.1568, 0.0419, 0.0242, 0.0069, 0.0070, 0.0356, 0.1101, 0.2378, 0.3003,\n",
      "        0.2378, 0.0599, 0.0658, 0.0555, 0.0274, 0.0407, 0.0738],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|█▎                                  | 11/313 [02:07<48:27,  9.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.2611, 0.2535, 0.0690, 0.0564, 0.1510, 0.1617, 0.3058, 0.1542, 0.0186,\n",
      "        0.0048, 0.0019, 0.0031, 0.0120, 0.0475, 0.1140, 0.0839],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|█▍                                  | 12/313 [02:15<45:34,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.7858, 0.7246, 0.3497, 0.0565, 0.0115, 0.0059, 0.0125, 0.0039, 0.0042,\n",
      "        0.0019, 0.0041, 0.0095, 0.1256, 0.5957, 0.7759, 0.6330],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|█▍                                  | 13/313 [02:20<40:05,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.1783, 0.3645, 0.4844, 0.1752, 0.3575, 0.3722, 0.0775, 0.0359, 0.1098,\n",
      "        0.1541, 0.0284, 0.0192, 0.0133, 0.0035, 0.0053, 0.0136],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|█▌                                  | 14/313 [02:26<36:45,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.0638, 0.0190, 0.0177, 0.0853, 0.0878, 0.0372, 0.1326, 0.0846, 0.3043,\n",
      "        0.3388, 0.0756, 0.0786, 0.3056, 0.1640, 0.4305, 0.3371],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|█▋                                  | 15/313 [02:33<35:27,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.0209, 0.0050, 0.0036, 0.0083, 0.1900, 0.6748, 0.9508, 0.9849, 0.9484,\n",
      "        0.6193, 0.4505, 0.1100, 0.2375, 0.2242, 0.0311, 0.0157],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|█▊                                  | 16/313 [02:39<33:37,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.4400, 0.0446, 0.0397, 0.0597, 0.1407, 0.3208, 0.1257, 0.0825, 0.0983,\n",
      "        0.3673, 0.1159, 0.0625, 0.0195, 0.0391, 0.4624, 0.3068],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   5%|█▉                                  | 17/313 [02:46<33:22,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.9685, 0.9616, 0.9119, 0.2179, 0.0716, 0.0306, 0.0379, 0.1021, 0.2256,\n",
      "        0.4721, 0.0986, 0.0290, 0.2410, 0.0627, 0.0521, 0.0724],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|██                                  | 18/313 [02:52<33:20,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([8.5696e-01, 2.8096e-01, 9.9313e-02, 2.7555e-03, 6.9232e-04, 1.4012e-03,\n",
      "        1.0073e-01, 4.5560e-01, 1.2307e-01, 1.6478e-01, 5.3124e-02, 1.5051e-01,\n",
      "        8.9529e-01, 8.7124e-01, 9.7990e-01, 9.5634e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|██▏                                 | 19/313 [02:59<33:10,  6.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.0335, 0.0581, 0.1807, 0.8289, 0.5855, 0.9073, 0.6916, 0.9717, 0.9800,\n",
      "        0.7412, 0.8234, 0.2320, 0.0503, 0.0637, 0.0196, 0.0462],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   6%|██▎                                 | 20/313 [03:06<33:22,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.1156, 0.7311, 0.7191, 0.0504, 0.1841, 0.0060, 0.0090, 0.1357, 0.3459,\n",
      "        0.1264, 0.0415, 0.1449, 0.8942, 0.9875, 0.9858, 0.9603],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|██▍                                 | 21/313 [03:14<34:23,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([6.9496e-02, 3.9702e-01, 7.7402e-01, 9.6822e-01, 6.9092e-01, 9.7538e-01,\n",
      "        9.7026e-01, 6.0388e-02, 1.3509e-03, 3.6457e-04, 1.6597e-03, 4.0440e-02,\n",
      "        9.7945e-01, 9.9850e-01, 9.9768e-01, 9.7132e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|██▌                                 | 22/313 [03:21<34:19,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([0.0438, 0.6569, 0.2791, 0.0052, 0.0036, 0.0783, 0.2745, 0.0043, 0.0030,\n",
      "        0.0301, 0.7568, 0.0283, 0.0033, 0.0026, 0.0077, 0.6719],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|██▋                                 | 23/313 [03:28<34:31,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([2.6346e-02, 4.4424e-01, 6.4140e-02, 3.1006e-01, 9.8084e-01, 9.5288e-01,\n",
      "        1.7057e-01, 8.1696e-01, 9.3508e-01, 2.0227e-01, 1.0051e-01, 1.5291e-03,\n",
      "        3.2790e-04, 3.9896e-03, 9.0614e-01, 9.6602e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|██▊                                 | 24/313 [03:34<33:15,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([1.0549e-01, 8.4046e-01, 6.7837e-01, 9.9721e-01, 9.9803e-01, 9.8339e-01,\n",
      "        6.9755e-02, 4.7134e-04, 3.4377e-04, 1.0167e-02, 1.6223e-01, 5.2934e-03,\n",
      "        2.5237e-03, 4.6320e-02, 9.1268e-01, 2.0409e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|██▉                                 | 25/313 [03:41<33:20,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([7.3746e-01, 3.3849e-03, 1.5245e-03, 6.3428e-01, 1.7168e-01, 9.7827e-01,\n",
      "        9.9484e-01, 9.9871e-01, 9.9110e-01, 2.1799e-01, 4.7566e-01, 7.7836e-03,\n",
      "        3.6850e-01, 3.2393e-01, 1.1071e-03, 8.3002e-04],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   8%|██▉                                 | 26/313 [03:48<32:07,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9624e-01, 9.0976e-01, 9.7386e-01, 3.4860e-02, 5.6372e-04, 2.8848e-04,\n",
      "        4.8322e-03, 9.1390e-01, 9.5865e-01, 5.2192e-03, 1.0104e-03, 3.5152e-04,\n",
      "        3.0479e-03, 9.7135e-01, 9.9703e-01, 7.4481e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|███                                 | 27/313 [03:54<32:02,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([2.2791e-02, 9.6532e-01, 9.7916e-01, 9.8151e-01, 9.9770e-01, 9.8658e-01,\n",
      "        3.2502e-02, 3.4322e-01, 1.8177e-02, 9.9110e-01, 9.7599e-01, 3.4564e-03,\n",
      "        7.6278e-05, 2.0286e-04, 5.4328e-02, 9.7389e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|███▏                                | 28/313 [04:01<32:07,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([5.5970e-04, 6.4528e-05, 5.1277e-05, 5.9035e-05, 1.6349e-03, 7.9955e-01,\n",
      "        9.9205e-01, 9.9899e-01, 9.8404e-01, 1.6982e-01, 6.8959e-04, 8.1795e-01,\n",
      "        9.9609e-01, 9.9896e-01, 9.9938e-01, 9.8040e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   9%|███▎                                | 29/313 [04:08<32:04,  6.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9714e-01, 4.2852e-01, 9.7686e-01, 2.9069e-01, 9.9719e-01, 9.9930e-01,\n",
      "        4.6381e-02, 1.8590e-03, 8.8762e-04, 4.4945e-03, 2.7257e-01, 3.1894e-03,\n",
      "        9.8866e-04, 1.0612e-03, 2.1437e-04, 1.1806e-03],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|███▍                                | 30/313 [04:15<32:30,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.8759e-01, 9.9965e-01, 9.8228e-01, 1.7157e-04, 9.1076e-04, 2.4700e-03,\n",
      "        9.9606e-01, 9.8397e-01, 2.5181e-03, 9.0955e-01, 1.7381e-04, 9.9029e-03,\n",
      "        4.0017e-04, 5.5541e-01, 9.8641e-01, 9.8818e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|███▌                                | 31/313 [04:22<32:00,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([1.7656e-04, 9.6910e-05, 1.1939e-01, 1.0123e-04, 3.2331e-03, 1.2567e-02,\n",
      "        9.9461e-01, 9.8605e-01, 3.6813e-01, 9.0866e-03, 9.8492e-01, 9.9786e-01,\n",
      "        9.9966e-01, 9.9655e-01, 3.9367e-03, 3.1054e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|███▋                                | 32/313 [04:28<30:55,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([8.9281e-04, 3.1528e-04, 6.9786e-01, 8.5669e-05, 4.5382e-03, 9.9623e-01,\n",
      "        9.9973e-01, 9.9977e-01, 9.9980e-01, 9.9715e-01, 2.8950e-03, 8.9057e-05,\n",
      "        6.4726e-04, 9.9436e-01, 9.8321e-01, 1.2567e-02],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|███▊                                | 33/313 [04:36<32:08,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([8.9509e-01, 5.6492e-04, 9.8509e-01, 9.4509e-01, 4.7563e-04, 9.9516e-01,\n",
      "        1.2265e-01, 9.9192e-01, 8.3317e-01, 2.6170e-03, 9.9960e-01, 9.8211e-01,\n",
      "        2.6531e-04, 3.7875e-04, 9.9459e-01, 9.8204e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|███▉                                | 34/313 [04:43<32:10,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9361e-01, 9.9546e-01, 4.7069e-04, 9.9546e-01, 2.3942e-04, 9.7393e-01,\n",
      "        9.9927e-01, 9.8921e-04, 1.2784e-04, 2.2731e-04, 1.7018e-03, 9.9645e-01,\n",
      "        9.8925e-01, 3.2819e-03, 9.9354e-01, 3.4800e-04],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|████                                | 35/313 [04:49<32:07,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9838e-01, 4.0708e-03, 9.9917e-01, 1.4881e-04, 6.8472e-04, 9.9995e-01,\n",
      "        7.6328e-03, 1.9045e-03, 9.9458e-01, 6.0432e-01, 9.4148e-04, 1.5131e-03,\n",
      "        4.4918e-02, 3.4215e-03, 9.9890e-01, 9.9907e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|████▏                               | 36/313 [04:57<32:36,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([1.2026e-01, 4.6328e-03, 9.9937e-01, 7.7718e-04, 5.5386e-02, 9.9993e-01,\n",
      "        1.7855e-02, 5.9571e-01, 1.4609e-03, 4.2028e-03, 1.3174e-03, 7.9723e-04,\n",
      "        7.5388e-03, 2.3026e-02, 9.9709e-01, 9.9959e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|████▎                               | 37/313 [05:04<32:34,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9731e-01, 1.5428e-04, 9.9931e-01, 2.9956e-03, 7.4466e-05, 9.9994e-01,\n",
      "        4.2640e-05, 9.9979e-01, 9.9979e-01, 9.4766e-05, 9.9904e-01, 1.9600e-04,\n",
      "        9.5682e-01, 9.9329e-01, 3.6027e-04, 9.9855e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|████▎                               | 38/313 [05:11<31:49,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9975e-01, 2.6228e-03, 3.6015e-03, 9.9983e-01, 9.9979e-01, 9.9877e-01,\n",
      "        3.8260e-03, 4.7443e-04, 9.9990e-01, 2.4074e-03, 9.9868e-01, 1.1503e-04,\n",
      "        1.1518e-03, 5.8987e-05, 1.5619e-04, 1.3521e-02],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|████▍                               | 39/313 [05:17<31:22,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([6.2750e-04, 2.4397e-04, 9.9943e-01, 1.2650e-04, 9.9947e-01, 2.2947e-04,\n",
      "        9.9990e-01, 9.9830e-01, 1.3033e-05, 9.9887e-01, 8.6299e-01, 4.1809e-05,\n",
      "        2.5736e-03, 9.9436e-01, 9.7377e-01, 9.9751e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|████▌                               | 40/313 [05:25<31:45,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([5.5761e-04, 2.2585e-04, 8.6928e-02, 2.6891e-03, 2.4766e-03, 6.4092e-03,\n",
      "        9.9992e-01, 1.6860e-04, 9.9987e-01, 9.9964e-01, 8.9795e-05, 1.1082e-03,\n",
      "        9.9996e-01, 9.9883e-01, 9.9552e-05, 2.4469e-02],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|████▋                               | 41/313 [05:32<31:52,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([1.9965e-03, 9.9992e-01, 2.0433e-02, 9.9815e-01, 6.8332e-06, 9.9986e-01,\n",
      "        9.9510e-01, 2.0649e-02, 2.5992e-04, 2.6730e-04, 7.3549e-04, 9.9985e-01,\n",
      "        9.9732e-01, 5.5839e-05, 1.2021e-05, 5.1912e-04],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  13%|████▊                               | 42/313 [05:39<32:47,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([9.9769e-01, 9.9990e-01, 9.9909e-01, 9.6963e-01, 1.6689e-05, 9.9994e-01,\n",
      "        2.0189e-05, 9.8841e-01, 5.9729e-06, 9.9990e-01, 7.7788e-06, 3.2644e-06,\n",
      "        4.3394e-05, 7.3748e-05, 9.9553e-01, 9.9871e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|████▉                               | 43/313 [05:46<31:59,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([3.9751e-05, 9.9733e-01, 9.8778e-01, 9.9836e-01, 3.2236e-06, 2.2005e-02,\n",
      "        8.0715e-06, 8.5616e-05, 9.8661e-01, 9.5098e-01, 9.9895e-01, 9.9986e-01,\n",
      "        9.6019e-01, 2.0721e-04, 5.8398e-04, 9.9987e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  14%|█████                               | 44/313 [05:53<31:57,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n",
      "torch.Size([16, 20416])\n",
      "torch.Size([16, 128])\n",
      "RNN torch.Size([16, 256])\n",
      "After FC2 torch.Size([16]) tensor([5.4406e-05, 3.3784e-05, 1.1650e-05, 1.1855e-04, 6.8704e-05, 9.9996e-01,\n",
      "        1.7139e-05, 5.1960e-05, 5.4848e-05, 4.9125e-05, 9.9104e-01, 9.9984e-01,\n",
      "        9.9223e-01, 8.7751e-05, 9.9987e-01, 9.9900e-01],\n",
      "       grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Save the model after each epoch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CRNN_Model(num_class=2, msr_size=(23, 8), rnn_hidden_size=128, dropout=0.7, tem_fac=[1, 2, 1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.double()\n",
    "model.to(device)\n",
    "\n",
    "# Train the model for a few epochs\n",
    "num_epochs = 2\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, criterion, optimizer, epoch)\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model after each epoch\n",
    "    torch.save(model.state_dict(), f\"crnn_model_epoch_{epoch}.pt\")\n",
    "\n",
    "    # Calculate EER using the ROC curve\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(train_loader, desc=\"Calculating EER\", leave=False):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data).cpu().numpy()\n",
    "            all_scores.extend(output)\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    fpr, fnr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    print(f\"Epoch {epoch}, Equal Error Rate (EER): {eer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fed1e5-8c32-4bfb-ac66-d407c0a59125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183f499-a023-446a-92ab-b2310eef9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate real and fake recordings\n",
    "real_recordings = train_df[train_df['target'] == 0]['filepath'].tolist()\n",
    "fake_recordings = train_df[train_df['target'] == 1]['filepath'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e6de6-8bac-43a7-aff7-77339d18c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy, r = process_file(real_recordings[1])\n",
    "    # Convert NumPy array to PyTorch tensor\n",
    "energy = torch.tensor(energy, dtype=torch.double)\n",
    "print(energy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c70119-afed-4973-af80-b3c7d43b3e36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e45ec52e-4e0d-4250-bbfd-989eaf91666d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN_Model(\n",
       "  (dp): Dropout(p=0.7, inplace=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (sig): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (downsample): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (CNNblock): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=20416, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.7, inplace=False)\n",
       "  )\n",
       "  (rnn1): GRU(128, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((256, 75), eps=1e-05, elementwise_affine=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=75, stride=75, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of your model\n",
    "loaded_model = CRNN_Model(num_class=2, msr_size=(23, 8), rnn_hidden_size=128, dropout=0.7, tem_fac=[1, 2, 1])\n",
    "\n",
    "# Specify the path to the saved model file\n",
    "model_path = \"crnn_model_epoch_1.pt\"\n",
    "\n",
    "# Load the model's state dictionary\n",
    "loaded_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c6187dd-c4d1-4963-8383-9741beb98fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating EER:   0%|                                     | 0/313 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23, 8, 58])\n",
      "torch.Size([16, 1, 23, 8, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert the data to double precision\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdouble()\n\u001b[0;32m----> 7\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m all_scores\u001b[38;5;241m.\u001b[39mextend(output)\n\u001b[1;32m      9\u001b[0m all_targets\u001b[38;5;241m.\u001b[39mextend(target\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[13], line 81\u001b[0m, in \u001b[0;36mCRNN_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 81\u001b[0m ot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Flatten ot to have shape (batch_size, -1)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m ot \u001b[38;5;241m=\u001b[39m ot\u001b[38;5;241m.\u001b[39mview(ot\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# Convert the input data to torch.double before passing it to the model\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(train_loader, desc=\"Calculating EER\", leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Convert the data to double precision\n",
    "        data = data.double()\n",
    "        output = loaded_model(data).cpu().numpy()\n",
    "        all_scores.extend(output)\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    fpr, fnr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fnr - fpr))]\n",
    "    print(f\"Epoch {epoch}, Equal Error Rate (EER): {eer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18f03e3d-2816-482e-995a-90829b6e1fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, 11)  # Assuming 10 epochs in this case\n",
    "\n",
    "train_loss = [0.5394, 0.5154, 0.5165, 0.5168, 0.5147, 0.5141, 0.5115, 0.5135, 0.5115, 0.5121]\n",
    "train_accuracy = [0.9302, 0.9884, 0.9840, 0.9828, 0.9880, 0.9914, 0.9958, 0.9920, 0.9960, 0.9950]\n",
    "train_eer = [0.0702, 0.0124, 0.0159, 0.0178, 0.0105, 0.0120, 0.0054, 0.0085, 0.0050, 0.0058]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot Training Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epochs, train_loss, marker='o')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plot Training Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epochs, train_accuracy, marker='o', color='r')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Plot Training EER\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epochs, train_eer, marker='o', color='g')\n",
    "plt.title('Training Equal Error Rate (EER)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('EER')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0c3c491-53d6-4cae-a0d9-e8d38ab869f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m CRNN_Model(num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, msr_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m8\u001b[39m), rnn_hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, tem_fac\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrnn_model_epoch_10.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Replace X with the desired epoch number\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval() \n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:789\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    788\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:1131\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1130\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1131\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:1101\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1100\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1101\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:1083\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1079\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39muntyped()\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1083\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1084\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:215\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 215\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = CRNN_Model(num_class=2, msr_size=(23, 8), rnn_hidden_size=128, dropout=0.7, tem_fac=[1, 2, 1])\n",
    "model.load_state_dict(torch.load(\"crnn_model_epoch_10.pt\"))  # Replace X with the desired epoch number\n",
    "model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34b0bb50-250b-4d3c-bd4d-f753b91f2f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN_Model(\n",
       "  (dp): Dropout(p=0.7, inplace=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (sig): Sigmoid()\n",
       "  (tanh): Tanh()\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (cnn3): Sequential(\n",
       "    (0): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU(inplace=True)\n",
       "  )\n",
       "  (downsample): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (CNNblock): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(2, 1, 1), stride=(2, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv3d(16, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (1): BatchNorm3d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): MaxPool3d(kernel_size=(1, 1, 1), stride=(1, 1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=20416, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.7, inplace=False)\n",
       "  )\n",
       "  (rnn1): GRU(128, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((256, 75), eps=1e-05, elementwise_affine=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=75, stride=75, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model on CPU\n",
    "model = CRNN_Model(num_class=2, msr_size=(23, 8), rnn_hidden_size=128, dropout=0.7, tem_fac=[1, 2, 1])\n",
    "model.load_state_dict(torch.load(\"crnn_model_epoch_10.pt\", map_location=torch.device('cpu')))  # Replace X with the desired epoch number\n",
    "model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e4248ad-c65c-4a11-bc5a-63c7d2743738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24844"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt',\n",
    "                       sep=\" \", header=None)\n",
    "test_df.columns =['speaker_id','filename','system_id','null','class_name']\n",
    "test_df.drop(columns=['null'],inplace=True)\n",
    "test_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_dev/flac/'+test_df.filename+'.flac'\n",
    "test_df['target'] = (test_df.class_name=='spoof').astype('int32')\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a814934a-7158-45a1-a425-252959ab995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SRMRDataset(test_df[:5000])\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eabd1521-d48d-45b2-98f0-7ee1d94169cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader):\n\u001b[1;32m      9\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Store true labels and predicted scores for EER calculation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     y_true\u001b[38;5;241m.\u001b[39mextend(target\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[47], line 82\u001b[0m, in \u001b[0;36mCRNN_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m ot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Flatten ot to have shape (batch_size, -1)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m ot \u001b[38;5;241m=\u001b[39m ot\u001b[38;5;241m.\u001b[39mview(ot\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# Prepare and process test data\n",
    "\n",
    "# Make predictions\n",
    "y_true = []\n",
    "y_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        \n",
    "        # Store true labels and predicted scores for EER calculation\n",
    "        y_true.extend(target.cpu().numpy())\n",
    "        y_scores.extend(output.cpu().detach().numpy())\n",
    "\n",
    "# Calculate EER\n",
    "eer = calculate_eer(np.array(y_true), np.array(y_scores))\n",
    "print(f\"Test EER: {eer:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "13dc54f4-e376-41e8-92f0-feb08dc01772",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m (output \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Assuming 0.5 threshold for binary classification\u001b[39;00m\n\u001b[1;32m      9\u001b[0m total_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted_labels \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[47], line 82\u001b[0m, in \u001b[0;36mCRNN_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m) \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m ot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCNNblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Flatten ot to have shape (batch_size, -1)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m ot \u001b[38;5;241m=\u001b[39m ot\u001b[38;5;241m.\u001b[39mview(ot\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cslab/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "    predicted_labels = (output > 0.5).float()  # Assuming 0.5 threshold for binary classification\n",
    "    total_correct += (predicted_labels == target).sum().item()\n",
    "    total_samples += target.size(0)\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc509201-89ec-4864-9d5d-809515ddf90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
