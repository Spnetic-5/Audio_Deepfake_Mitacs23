{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ba074f-0d6d-40fa-b848-79683c0d1296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import hamming\n",
    "from srmrpy.hilbert import hilbert\n",
    "from srmrpy.modulation_filters import *\n",
    "from gammatone.fftweight import fft_gtgram\n",
    "from gammatone.filters import centre_freqs, make_erb_filters, erb_filterbank\n",
    "from srmrpy.segmentaxis import segment_axis\n",
    "from scipy.io.wavfile import read as readwav\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9d5000-2211-4de1-9dfb-1d6d976c1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_erbs(low_freq, fs, n_filters):\n",
    "    ear_q = 9.26449 # Glasberg and Moore Parameters\n",
    "    min_bw = 24.7\n",
    "    order = 1\n",
    "\n",
    "    erbs = ((centre_freqs(fs, n_filters, low_freq)/ear_q)**order + min_bw**order)**(1/order)\n",
    "    return erbs\n",
    "\n",
    "def calc_cutoffs(cfs, fs, q):\n",
    "    # Calculates cutoff frequencies (3 dB) for 2nd order bandpass\n",
    "    w0 = 2*np.pi*cfs/fs\n",
    "    B0 = np.tan(w0/2)/q\n",
    "    L = cfs - (B0 * fs / (2*np.pi))\n",
    "    R = cfs + (B0 * fs / (2*np.pi))\n",
    "    return L, R\n",
    "\n",
    "def normalize_energy(energy, drange=30.0):\n",
    "    peak_energy = np.max(np.mean(energy, axis=0))\n",
    "    min_energy = peak_energy*10.0**(-drange/10.0)\n",
    "    energy[energy < min_energy] = min_energy\n",
    "    energy[energy > peak_energy] = peak_energy\n",
    "    return energy\n",
    "\n",
    "def srmr(x, fs, n_cochlear_filters=23, low_freq=125, min_cf=4, max_cf=128, fast=True, norm=False):\n",
    "    wLengthS = .256\n",
    "    wIncS = .064\n",
    "    # Computing gammatone envelopes\n",
    "    if fast:\n",
    "        mfs = 400.0\n",
    "        gt_env = fft_gtgram(x, fs, 0.010, 0.0025, n_cochlear_filters, low_freq)\n",
    "    else:\n",
    "        cfs = centre_freqs(fs, n_cochlear_filters, low_freq)\n",
    "        fcoefs = make_erb_filters(fs, cfs)\n",
    "        gt_env = np.abs(hilbert(erb_filterbank(x, fcoefs)))\n",
    "        mfs = fs\n",
    "\n",
    "    wLength = int(np.ceil(wLengthS*mfs))\n",
    "    wInc = int(np.ceil(wIncS*mfs))\n",
    "\n",
    "    # Computing modulation filterbank with Q = 2 and 8 channels\n",
    "    mod_filter_cfs = compute_modulation_cfs(min_cf, max_cf, 8)\n",
    "    MF = modulation_filterbank(mod_filter_cfs, mfs, 2)\n",
    "\n",
    "    n_frames = int(1 + (gt_env.shape[1] - wLength)//wInc)\n",
    "    w = hamming(wLength+1)[:-1] # window is periodic, not symmetric\n",
    "\n",
    "    energy = np.zeros((n_cochlear_filters, 8, n_frames))\n",
    "    for i, ac_ch in enumerate(gt_env):\n",
    "        mod_out = modfilt(MF, ac_ch)\n",
    "        for j, mod_ch in enumerate(mod_out):\n",
    "            mod_out_frame = segment_axis(mod_ch, wLength, overlap=wLength-wInc, end='pad')\n",
    "            energy[i,j,:] = np.sum((w*mod_out_frame[:n_frames])**2, axis=1)\n",
    "\n",
    "    if norm:\n",
    "        energy = normalize_energy(energy)\n",
    "\n",
    "    erbs = np.flipud(calc_erbs(low_freq, fs, n_cochlear_filters))\n",
    "\n",
    "    avg_energy = np.mean(energy, axis=2)\n",
    "    total_energy = np.sum(avg_energy)\n",
    "\n",
    "    AC_energy = np.sum(avg_energy, axis=1)\n",
    "    AC_perc = AC_energy*100/total_energy\n",
    "\n",
    "    AC_perc_cumsum=np.cumsum(np.flipud(AC_perc))\n",
    "    K90perc_idx = np.where(AC_perc_cumsum>90)[0][0]\n",
    "\n",
    "    BW = erbs[K90perc_idx]\n",
    "\n",
    "    cutoffs = calc_cutoffs(mod_filter_cfs, fs, 2)[0]\n",
    "\n",
    "    if (BW > cutoffs[4]) and (BW < cutoffs[5]):\n",
    "        Kstar=5\n",
    "    elif (BW > cutoffs[5]) and (BW < cutoffs[6]):\n",
    "        Kstar=6\n",
    "    elif (BW > cutoffs[6]) and (BW < cutoffs[7]):\n",
    "        Kstar=7\n",
    "    elif (BW > cutoffs[7]):\n",
    "        Kstar=8\n",
    "\n",
    "    return np.sum(avg_energy[:, :4])/np.sum(avg_energy[:, 4:Kstar]), energy\n",
    "\n",
    "\n",
    "def read_audio_file(filename, max_length=64600):\n",
    "    # Use soundfile to read the .flac audio file\n",
    "    audio_data, fs = sf.read(filename, always_2d=True, dtype='float32')\n",
    "    # Normalize the audio data to the range [-1, 1]\n",
    "    audio_data /= np.max(np.abs(audio_data))\n",
    "\n",
    "    # Pad or truncate audio data to the desired max_length\n",
    "    if len(audio_data) < max_length:\n",
    "        padding = max_length - len(audio_data)\n",
    "        audio_data = np.pad(audio_data, ((0, padding), (0, 0)), mode='constant')\n",
    "    elif len(audio_data) > max_length:\n",
    "        audio_data = audio_data[:max_length, :]\n",
    "    return fs, audio_data\n",
    "\n",
    "def process_file(f, n_cochlear_filters=23, low_freq=125, min_cf=4, max_cf=128, fast=True, norm=True):\n",
    "    fs, s = read_audio_file(f)  # Use read_audio_file to handle .flac files\n",
    "    if len(s.shape) > 1:\n",
    "        s = s[:, 0]\n",
    "    r, energy = srmr(s, fs, n_cochlear_filters=n_cochlear_filters,\n",
    "                     min_cf=min_cf,\n",
    "                     max_cf=max_cf,\n",
    "                     fast=fast,\n",
    "                     norm=norm)\n",
    "    return energy, r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f20c04-cffb-4987-b0be-d1bbed91faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/home/sspowar/scratch/archive/LA/LA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00145a83-1646-4622-8d47-b5403b620132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 25380\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "train_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt',\n",
    "                       sep=\" \", header=None)\n",
    "train_df.columns =['speaker_id','filename','system_id','type','class_name']\n",
    "# train_df.drop(columns=['null'],inplace=True)\n",
    "train_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_train/flac/'+train_df.filename+'.flac'\n",
    "train_df['target'] = (train_df.class_name=='spoof').astype('int32') # set labels 1 for fake and 0 for real\n",
    "print(f'Train Samples: {len(train_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826899a5-b8d4-4bba-b5cd-adf337d1edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25380"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_recordings = train_df['filepath'].tolist()\n",
    "len(train_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7850f593-58e7-4e45-ae1c-cf571bafae4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Samples: 24844\n"
     ]
    }
   ],
   "source": [
    "# VALID\n",
    "\n",
    "valid_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt',\n",
    "                       sep=\" \", header=None)\n",
    "valid_df.columns =['speaker_id','filename','system_id','null','class_name']\n",
    "valid_df.drop(columns=['null'],inplace=True)\n",
    "valid_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_dev/flac/'+valid_df.filename+'.flac'\n",
    "print(f'Valid Samples: {len(valid_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1148be-4f88-43bd-a7ec-4ccf3e56b735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24844"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_recordings = valid_df['filepath'].tolist()\n",
    "len(valid_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ac7b07-9cfe-4bc4-b1ed-af2be5356ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Samples: 71237\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt',\n",
    "                       sep=\" \", header=None)\n",
    "test_df.columns =['speaker_id','filename','system_id','null','class_name']\n",
    "test_df.drop(columns=['null'],inplace=True)\n",
    "test_df['filepath'] = f'{BASE_PATH}/ASVspoof2019_LA_eval/flac/'+test_df.filename+'.flac'\n",
    "test_df['target'] = (test_df.class_name=='spoof').astype('int32')\n",
    "print(f'Test Samples: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c10040-ed68-4f6d-a82f-e69419fc950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_recordings = test_df['filepath'].tolist()\n",
    "len(test_recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9a69b7-f2a0-40ff-adea-899a1f833288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def generate_tensorgrams(recordings, save_path):\n",
    "    n_recordings = len(recordings)\n",
    "    \n",
    "    for recording in tqdm(recordings, desc=\"Calculating SRMR\", unit=\"file\", leave=False):\n",
    "        energy, r = process_file(recording)\n",
    "        \n",
    "        # Create a filename based on the recording's name\n",
    "        filename = os.path.basename(recording).split('.')[0]\n",
    "        \n",
    "        # Save the energy array as a NumPy binary file in the specified folder\n",
    "        save_filename = os.path.join(save_path, f\"{filename}_energy.npy\")\n",
    "        np.save(save_filename, energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7650dc2e-b011-4609-9520-3ae6c7f15637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sspowar/scratch/archive/LA/LA/ASVspoof2019_LA_train/flac/LA_T_1138215.flac\n",
      "/home/sspowar/scratch/archive/LA/LA/ASVspoof2019_LA_dev/flac/LA_D_1047731.flac\n",
      "/home/sspowar/scratch/archive/LA/LA/ASVspoof2019_LA_eval/flac/LA_E_2834763.flac\n",
      "LA_T_1138215\n"
     ]
    }
   ],
   "source": [
    "print(train_recordings[0])\n",
    "print(valid_recordings[0])\n",
    "print(test_recordings[0])\n",
    "print(os.path.basename(train_recordings[0]).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19303ea7-e0c0-4bfa-b1e5-9103cf2ea4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating SRMR:  39%|████████▏            | 9836/25380 [23:54<41:04,  6.31file/s]"
     ]
    }
   ],
   "source": [
    "generate_tensorgrams(train_recordings, '/home/sspowar/scratch/train_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a53f9-3295-4bef-841a-c9884c0d9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tensorgrams(valid_recordings, '/home/sspowar/scratch/valid_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb48851-f514-4aae-be71-c6225c659b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_tensorgrams(test_recordings, '/home/sspowar/scratch/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd40448-a46c-4a81-9d2f-eceefb10290e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
